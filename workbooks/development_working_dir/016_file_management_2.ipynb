{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Management 2\n",
    "\n",
    "## Pandas File Access\n",
    "\n",
    "We've already looked at our main tool for reading data from disk, the file read/write functionality in Pandas. When reading datasets this is normally all we need. Inside the read_csv function the Pandas people have either created all the file access stuff that they need to read a CSV or, more likely, they repurposed and extended some os library functions to do the work for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>item_name</th>\n",
       "      <th>choice_description</th>\n",
       "      <th>item_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Chips and Fresh Tomato Salsa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Izze</td>\n",
       "      <td>[Clementine]</td>\n",
       "      <td>$3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Nantucket Nectar</td>\n",
       "      <td>[Apple]</td>\n",
       "      <td>$3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Chips and Tomatillo-Green Chili Salsa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Chicken Bowl</td>\n",
       "      <td>[Tomatillo-Red Chili Salsa (Hot), [Black Beans...</td>\n",
       "      <td>$16.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  quantity                              item_name  \\\n",
       "0         1         1           Chips and Fresh Tomato Salsa   \n",
       "1         1         1                                   Izze   \n",
       "2         1         1                       Nantucket Nectar   \n",
       "3         1         1  Chips and Tomatillo-Green Chili Salsa   \n",
       "4         2         2                           Chicken Bowl   \n",
       "\n",
       "                                  choice_description item_price  \n",
       "0                                                NaN     $2.39   \n",
       "1                                       [Clementine]     $3.39   \n",
       "2                                            [Apple]     $3.39   \n",
       "3                                                NaN     $2.39   \n",
       "4  [Tomatillo-Red Chili Salsa (Hot), [Black Beans...    $16.98   "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"chipotle.tsv\", sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OS and File Read/Write\n",
    "\n",
    "We can also use the `os` module to do some basic file management. OS is a library that allows us to interact with the operating system on our local computer. Recall that our Python programs run inside an environment setup by the Python install on our computer. This means that as we work we are \"inside\" that separate environment and we can't directly interact with the underlying computer. The os library, and functions such as read_csv from other libraries, are a tool that allows us to bridge this gap. The os library that is presented to us gives us an assortment of commands to do things like delete files or change the directory we're using. The library's functions are then translated into the correct actions for the actual computer, and passed on to that computer, when the code is run in the Python environment. This also allows for Python code to be portable, or able to run with few to no changes, on different types of computers - I am using a Mac, most of you are probably using a PC, and we can also use a Unix/Linux based system like Google Colab. The code we write can work on all of those environments because of this abstraction, and in each case, the actions triggered by the os module will be different depending on the underlying operating system of the machine. In practice, many of the user-friendly libraries that we might use to access files or folders is built on top of the os module, so we often avoid needing to get into the weeds ourselves.\n",
    "\n",
    "We can use the `os` module to do things like:\n",
    "<ul>\n",
    "    <li>Get the current working directory</li>\n",
    "    <li>Change the current working directory</li>\n",
    "    <li>Get a list of files in a directory</li>\n",
    "    <li>Create a new directory</li>\n",
    "    <li>Remove a directory</li>\n",
    "    <li>Remove a file</li>\n",
    "</ul>\n",
    "\n",
    "First though, let's get some info about our system. Everyone will get totally different results here - I'm on a MacBook Air running MacOS, and I assume most of you have some variety of a PC running Windows. If you've ever seen any of those website things that tells you, \"You are running Windows 10 in Edmonton, Ab...\" this is a similar idea. The os.uname() function reaches out to the computer and retrieves some of it's identifying information for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Darwin\n",
      "Akeems-Air.nait.ca\n",
      "22.5.0\n",
      "Darwin Kernel Version 22.5.0: Mon Apr 24 20:52:43 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8112\n",
      "arm64\n"
     ]
    }
   ],
   "source": [
    "for a in os.uname():\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folder Management\n",
    "\n",
    "The OS library also provides for an assortment of folder management functions. We can use these to create, rename, and delete folders.\n",
    "\n",
    "When using large datasets it is very common to have our data distributed over several folders. For example, if we are doing image recognition we might have a folder for \"dogs\", another with \"cars\", and another with \"rutabagas\". To construct our dataset we need to navigate over all of these folders and read in the files, using os and/or some similar libraries. \n",
    "\n",
    "Some common folder actions are:\n",
    "<ul>\n",
    "<li> os.mkdir() - create a new folder </li>\n",
    "<li> os.rename() - rename a folder </li>\n",
    "<li> os.rmdir() - remove a folder </li>\n",
    "<li> os.getcwd() - get the current working directory </li>\n",
    "<li> os.chdir() - change the current working directory </li>\n",
    "<li> os.listdir() - list the contents of a directory </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/akeem/Documents/GitHub/Programming_Basics_for_ML/workbooks/development_working_dir'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note:</b> when using these functions, you need to be careful about where you are in the file system. In particular, the folder location doesn't reset itself automatically if you rerun everything. We need to restart the environment to reset the working directory, or navigate ourselves back to the correct location. The above command got the current working directory back from the Python environment, which in turn got it from the operating system. If we make a change to that directory, then rerun the above cell, we aren't \"reset\" to the original where we were when we started the program. To do that, we'd need to restart the environment, which would kill this current world in which our program is running, and generate a brand new one. \n",
    "\n",
    "Here I'm going to capture the current folder name and then move one level up, and back down. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "development_working_dir\n"
     ]
    }
   ],
   "source": [
    "org_fold = os.getcwd()\n",
    "tmp = os.getcwd().split(\"/\")[-1]\n",
    "print(tmp)\n",
    "os.chdir(\"../\")\n",
    "os.getcwd()\n",
    "os.chdir(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling File System Data\n",
    "\n",
    "We can also capture some of this information, and use it as a variable in our code that we can use to navigate the file system. For example, when grabbing the working directory above we stored it as a string and used the split command to break it into a hierarchy of folder names. Below we can pull the files in a folder and that data is returned in a list. If we have code where we need to jump around from folder to folder, we can use this list to help us navigate. For example, if we have a folder structure like this:\n",
    "\n",
    "```\n",
    "data\n",
    "    - dogs\n",
    "        - dog1.jpg\n",
    "        - dog2.jpg\n",
    "        - dog3.jpg\n",
    "    - cats\n",
    "        - cat1.jpg\n",
    "        - cat2.jpg\n",
    "        - cat3.jpg\n",
    "    - rutabagas\n",
    "        - rutabaga1.jpg\n",
    "        - rutabaga2.jpg\n",
    "        - rutabaga3.jpg\n",
    "```\n",
    "Our \"base\" folder is the data folder, and the subfolders inside are where we'll likely need to do all of our work. We can keep this map of the folder structure in some data structure, then we can use that info to move around. For example, we can find out where we are, visit each subfolder to do some work, and then move back to the base folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flies: 38\n",
      "\n",
      "010_class_comments.ipynb\n",
      "Clothing.csv\n",
      "file_list\n",
      "005_file_access.ipynb\n",
      "006_objects.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Capture file list\n",
    "# Print 5\n",
    "#<b>Bonus:</b> at some point when we looked at strings, someone asked about putting a newline in an f string. I was wrong, it can work like this, no workarounds needed. \n",
    "file_list = os.listdir()\n",
    "print(f\"Number of flies: {len(file_list)}\\n\")\n",
    "for file in range(5):\n",
    "    print(file_list[file])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing Text Files\n",
    "\n",
    "Now that we have an idea what is in our folders, we can start recklessly changing things. For example, we can use the os write functions to make a new CSV file and write some data to it. One thing that is reveled to us here that might not be visible is you're used to Windows machines is a look at what is a \"text\" file. Text files are .txt, but also .csv, .tsv, .py, etc... meaning all of these types of files is made up of just plain text, and we can edit them in any text editor on a computer - the file extension doesn't dictate it, that's for our convenience. The structure of our code will:\n",
    "<ul>\n",
    "<li> Open a connection to the file, if it doesn't exist this will create it. </li>\n",
    "<li> Perform the contents of the loop - writing some data to a file for 100 lines. </li>\n",
    "<li> When that writing task is complete, it will close the connection automatically thanks to the with. </li>\n",
    "</ul>\n",
    "\n",
    "In the open() function call to connect to the file we provide the second argument that defines what type of access we get to the file we are opening:\n",
    "<ul>\n",
    "<b><li> 'r' - read only </li>\n",
    "<li> 'w' - write only </li>\n",
    "<li> 'a' - append to the end of the file </li>\n",
    "<li> 'r+' - read and write </li></b>\n",
    "<li> 'w+' - write and read, overwrites existing files</li>\n",
    "</ul>\n",
    "\n",
    "These are mostly pretty simple and self-explanatory, with the exception of the distinction between r+ and w. The 'r+' option is a bit more complicated. This will open the file for reading and writing, but it will not create the file if it doesn't exist. If you try to open a file that doesn't exist with 'r+' you will get an error. The `w` option will create the file if it doesn't exist, but it will also overwrite the file if it does exist. So if we are making something brand new, we want `w`, but if we are attempting to update an existing file, we want `r+`. This is an easy place to make an error, so we should be careful. We can also check to see if the file we want to make already exists, then make a decision. `W+` is another weird option, it is read/write, but will overwrite the file if it exists.\n",
    "\n",
    "![File Permissions](../../images/file_permissions.png \"File Permissions\" )\n",
    "![File Permissions](../images/file_permissions.png \"File Permissions\" )\n",
    "\n",
    "Choosing the level of access of a file that we open is important in terms of writing our code to prevent errors. We want to open the file with the least impactful level of access that we need to have to do what we want. So if we are just reading data from a file, opening it as read only will prevent us accidentally changing that file in any way, as we don't even have the ability to do so. If we want a brand-new file, opening it as write only will prevent any old data that may have been hanging around from persisting. The more flexible the level of access, the more options we have for what we can do, the more likely it is that we may do something unintentional.\n",
    "\n",
    "<b>Note:</b> this will go to our current directory, wherever the pointer is, so if you got rid of that line to reset the locations, it would spit this file out to whatever folder you happen to be in.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 1\n",
    "os.chdir(org_fold)\n",
    "with open(\"fib.csv\", \"r+\") as f:\n",
    "    str(q) + \",\" + str(q) + \"\\n\"\n",
    "    for i in range(100):\n",
    "        if q == 1:\n",
    "            f.write(str(i+1) + \",\" + str(q) + \"\\n\")\n",
    "            q += 1\n",
    "        else:\n",
    "            q += 1\n",
    "            f.write(str(i+1) + \",\" + str(q) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Our File\n",
    "\n",
    "Now that our file is written, we can read it and see what we got. We need to specify the `r` here, since we are only reading. When reading from a file, there's a few main options:\n",
    "<ul>\n",
    "<li> read() - read the entire file into a single string </li>\n",
    "<li> readline() - read the file one line at a time </li>\n",
    "<li> readlines() - read the file into a list of strings, one per line </li>\n",
    "</ul>\n",
    "\n",
    "The first, read, takes in the entire file into one string. This is fine for small files, but for things that are large it is unruly. For most things of size we probably want to navigate the file one line at a time, using the readline() option. There's also a common shortcut that we can do with a for loop that does this for us easily:\n",
    "    \n",
    "    ``` for line in file: ```   \n",
    "\n",
    "If we are reading in a large file, one line at a time is a better choice. Depending on what we are doing, we may be able to process our data and \"deal with it\" - whether that be saving it to another file or loading it into some dataset - on the fly. When we get to neural networks towards the end of machine learning, we'll try to read enough data so that our processor is busy - so the computer is never waiting for either data or a free processor. Loading batches allows us to make the most of the power of our computer, as we can minimize the amount of time any part of it spends waiting for something else to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,1\n",
      "\n",
      "2,3\n",
      "\n",
      "3,4\n",
      "\n",
      "4,5\n",
      "\n",
      "5,6\n",
      "\n",
      "6,7\n",
      "\n",
      "7,8\n",
      "\n",
      "8,9\n",
      "\n",
      "9,10\n",
      "\n",
      "10,11\n",
      "\n",
      "11,12\n",
      "\n",
      "12,13\n",
      "\n",
      "13,14\n",
      "\n",
      "14,15\n",
      "\n",
      "15,16\n",
      "\n",
      "16,17\n",
      "\n",
      "17,18\n",
      "\n",
      "18,19\n",
      "\n",
      "19,20\n",
      "\n",
      "20,21\n",
      "\n",
      "21,22\n",
      "\n",
      "22,23\n",
      "\n",
      "23,24\n",
      "\n",
      "24,25\n",
      "\n",
      "25,26\n",
      "\n",
      "26,27\n",
      "\n",
      "27,28\n",
      "\n",
      "28,29\n",
      "\n",
      "29,30\n",
      "\n",
      "30,31\n",
      "\n",
      "31,32\n",
      "\n",
      "32,33\n",
      "\n",
      "33,34\n",
      "\n",
      "34,35\n",
      "\n",
      "35,36\n",
      "\n",
      "36,37\n",
      "\n",
      "37,38\n",
      "\n",
      "38,39\n",
      "\n",
      "39,40\n",
      "\n",
      "40,41\n",
      "\n",
      "41,42\n",
      "\n",
      "42,43\n",
      "\n",
      "43,44\n",
      "\n",
      "44,45\n",
      "\n",
      "45,46\n",
      "\n",
      "46,47\n",
      "\n",
      "47,48\n",
      "\n",
      "48,49\n",
      "\n",
      "49,50\n",
      "\n",
      "50,51\n",
      "\n",
      "51,52\n",
      "\n",
      "52,53\n",
      "\n",
      "53,54\n",
      "\n",
      "54,55\n",
      "\n",
      "55,56\n",
      "\n",
      "56,57\n",
      "\n",
      "57,58\n",
      "\n",
      "58,59\n",
      "\n",
      "59,60\n",
      "\n",
      "60,61\n",
      "\n",
      "61,62\n",
      "\n",
      "62,63\n",
      "\n",
      "63,64\n",
      "\n",
      "64,65\n",
      "\n",
      "65,66\n",
      "\n",
      "66,67\n",
      "\n",
      "67,68\n",
      "\n",
      "68,69\n",
      "\n",
      "69,70\n",
      "\n",
      "70,71\n",
      "\n",
      "71,72\n",
      "\n",
      "72,73\n",
      "\n",
      "73,74\n",
      "\n",
      "74,75\n",
      "\n",
      "75,76\n",
      "\n",
      "76,77\n",
      "\n",
      "77,78\n",
      "\n",
      "78,79\n",
      "\n",
      "79,80\n",
      "\n",
      "80,81\n",
      "\n",
      "81,82\n",
      "\n",
      "82,83\n",
      "\n",
      "83,84\n",
      "\n",
      "84,85\n",
      "\n",
      "85,86\n",
      "\n",
      "86,87\n",
      "\n",
      "87,88\n",
      "\n",
      "88,89\n",
      "\n",
      "89,90\n",
      "\n",
      "90,91\n",
      "\n",
      "91,92\n",
      "\n",
      "92,93\n",
      "\n",
      "93,94\n",
      "\n",
      "94,95\n",
      "\n",
      "95,96\n",
      "\n",
      "96,97\n",
      "\n",
      "97,98\n",
      "\n",
      "98,99\n",
      "\n",
      "99,100\n",
      "\n",
      "100,101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"fib.csv\", \"r\") as f:\n",
    "   for line in f:\n",
    "      print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appending a File and the In-File Pointer\n",
    "\n",
    "Another of the options above that is a little odd is the `a`, for append. This will open the file and add new data to the end of it, but it will not overwrite the existing data. This is useful if we want to add new data to an existing file, but we don't want to lose the old data. This is very useful for things like logs - we likely have a pretty substantial amount of data accumulated in a big text file and we want to add new stuff without losing the old data or having to deal with the old data at all. We can use this to basically tack some entries onto the end of a file easily.\n",
    "\n",
    "This issue of opening an existing file normally vs appending seems pretty minor, but it can have larger performance implications than we might expect. For example, server logs can be many, many GB of text that lists errors or warnings going back years. We want to keep the log, and we also want to add today's entries. Opening a 2GB file \"normally\", navigating to the end, then spitting it back out can be slow, appending directly to the end of that same file is fast. This is because just like navigating a file system, a text file itself has a pointer that maintains your position - think of it as an invisible cursor just like we have in any program where we type. Append puts that position cursor directly at the end, and just starts writing. Personally, I once had a job where I remade a little program that went to approximately 150 servers, grabbed their log file, and looked for last night's entry at the end of the file to see if a backup failed. By changing it from opening the files normally, to appending (roughly, the language wasn't Python), I cut the runtime from 4 to 5 hours to about <10 minutes - without making any actual improvements to the logic of the code, just by jumping directly to the end of the text. When someone wrote the original, all the log files were probably tiny, as the system was new, so it didn't matter for performance; as things grew, this became an issue.  \n",
    "\n",
    "<b>Note:</b> the \"it's slow to open a large file and write to the end\" thing is obviously a common issue for computers in general. File access packages know this, and are built to be fast no matter what. This idea is still true, just less true than it is with older software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"fib.csv\", \"a\") as f:\n",
    "#    print(f.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remote Data\n",
    "\n",
    "We can also use some code to programmatically download data from the internet. This can save us from having to download large files, but it can also help us to build automated pipelines for getting data. \n",
    "\n",
    "One thing that I've worked on a lot in industry is importing data from other systems into LMS systems like Moodle. A common process to do this is for the other system to export a CSV file to a specific location on a file server, then a script that we created will grab the new file from the pre-defined location and feed it into our import work. Applications for personal use are also broad - we could automate downloads of files that are regularly updated. \n",
    "\n",
    "For pretty much any data source that we might want to be able to access, there is likely a library that will do so. So we can access FTP servers, different file share protocols, and so on - we just need to look up the correct tool for whichever data source we want to access.\n",
    "\n",
    "<b>Note:</b> there are many libraries that download files, they're pretty much interchangeable. I'm using `urllib.request` here because it's built into Python and is the \"basic standard\", but you could also use `requests` or `wget` or `curl` or any number of other libraries. For this, and the others, look at the documentation to see the options and how to use the functions - they are generally similar to this, just provide a URL and a destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download\n",
    "url = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n",
    "import urllib.request\n",
    "try:\n",
    "    urllib.request.urlretrieve(url, 'chipotle.tsv')\n",
    "except:\n",
    "    print(\"Error downloading file\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compression\n",
    "\n",
    "Many files that we deal with, particularly when downloading datasets, may be compressed. Several libraries provide tools for us to programmatically deal with these files, including decompressing them and moving their files into our working directory.\n",
    "\n",
    "<b>Note:</b> Pandas read_csv function can also read compressed files directly, so you can load my_data.zip or similar with no interim decompression step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress some files\n",
    "import zipfile\n",
    "\n",
    "# Zip first 5 files in file_list\n",
    "with zipfile.ZipFile('file_list.zip', 'w') as myzip:\n",
    "    for file in range(5):\n",
    "        myzip.write(file_list[file])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompress into a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompress file_list.zip into file_list folder\n",
    "with zipfile.ZipFile('file_list.zip', 'r') as myzip:\n",
    "    myzip.extractall('file_list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete the New Folder\n",
    "\n",
    "We can delete that folder we just extracted, as well as the zip itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for file in os.listdir('file_list'):\n",
    "#    print(file)\n",
    "#    os.remove(file)\n",
    "#os.rmdir('file_list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and decompress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shutil\n",
    "\n",
    "The shutil library is another built-in package in Python that provides some tools to access files as well. The shutil library is a higher-level interface to the file system than the os library, meaning we get an additional layer of abstraction and more human-readable commands. Some of the key things we may want to use shutil for are things that we can do with the os, but it is a bit easier to do with shutil:\n",
    "<ul>\n",
    "<li>Copying files</li>\n",
    "<li>Moving files</li>\n",
    "<li>Removing files</li>\n",
    "<li>Creating archives</li>\n",
    "<li>Extracting from archives</li>\n",
    "</ul>\n",
    "\n",
    "The actions in the shutil package are more similar to how we probably think of things working as an end user looking at files on our computer, while the os package is more similar to the details of how the computer actually works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Delete File List Folder\n",
    "#try:\n",
    "#    shutil.rmtree('file_list')\n",
    "#except:\n",
    "#    print(\"File List Folder Does Not Exist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "usage(total=994662584320, used=184396263424, free=810266320896)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disk = shutil.disk_usage(os.getcwd())\n",
    "disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the shutil library to delete some of the stuff we created above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
